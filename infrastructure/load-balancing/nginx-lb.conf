# =============================================================================
# Howlerops - nginx Load Balancer Configuration
# =============================================================================
# Production load balancer for distributing traffic across backend instances
# =============================================================================

user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

# Performance tuning
worker_rlimit_nofile 65535;

events {
    worker_connections 4096;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    log_format upstream '$remote_addr - $remote_user [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" '
                        'upstream_addr=$upstream_addr '
                        'upstream_status=$upstream_status '
                        'request_time=$request_time '
                        'upstream_response_time=$upstream_response_time '
                        'upstream_connect_time=$upstream_connect_time '
                        'upstream_header_time=$upstream_header_time';

    access_log /var/log/nginx/access.log upstream;

    # Performance settings
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    keepalive_requests 100;
    reset_timedout_connection on;

    # Request limits
    client_max_body_size 10m;
    client_body_timeout 60s;
    client_header_timeout 60s;
    send_timeout 60s;

    # Hide nginx version
    server_tokens off;

    # ==========================================================================
    # Backend Upstream - API Servers
    # ==========================================================================
    upstream backend_api {
        # Load balancing method
        # Options: round_robin (default), least_conn, ip_hash, hash
        least_conn;  # Route to server with least active connections

        # Backend servers
        # Replace with actual backend IPs/hostnames
        server backend-1:8500 max_fails=3 fail_timeout=30s weight=1;
        server backend-2:8500 max_fails=3 fail_timeout=30s weight=1;
        server backend-3:8500 max_fails=3 fail_timeout=30s weight=1 backup;

        # Connection pooling
        keepalive 32;
        keepalive_requests 100;
        keepalive_timeout 60s;

        # Health check (nginx plus only)
        # health_check interval=5s fails=2 passes=2 uri=/health match=health_ok;

        # Slow start (gradually increase traffic to recovering server)
        # slow_start=30s;  # nginx plus only
    }

    # ==========================================================================
    # Frontend Upstream - Web Servers
    # ==========================================================================
    upstream frontend_web {
        least_conn;

        server frontend-1:80 max_fails=2 fail_timeout=30s;
        server frontend-2:80 max_fails=2 fail_timeout=30s;

        keepalive 16;
    }

    # ==========================================================================
    # Proxy Cache Configuration
    # ==========================================================================
    proxy_cache_path /var/cache/nginx/api
                     levels=1:2
                     keys_zone=api_cache:10m
                     max_size=1g
                     inactive=60m
                     use_temp_path=off;

    proxy_cache_path /var/cache/nginx/static
                     levels=1:2
                     keys_zone=static_cache:20m
                     max_size=5g
                     inactive=7d
                     use_temp_path=off;

    # Cache key
    proxy_cache_key "$scheme$request_method$host$request_uri";

    # Cache methods
    proxy_cache_methods GET HEAD;

    # Cache lock (prevent cache stampede)
    proxy_cache_lock on;
    proxy_cache_lock_timeout 5s;

    # Use stale cache when backend is down
    proxy_cache_use_stale error timeout invalid_header updating
                          http_500 http_502 http_503 http_504;

    # Background cache updates
    proxy_cache_background_update on;

    # Cache revalidation
    proxy_cache_revalidate on;

    # ==========================================================================
    # Rate Limiting
    # ==========================================================================
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=30r/s;
    limit_req_zone $binary_remote_addr zone=auth_limit:10m rate=5r/m;
    limit_conn_zone $binary_remote_addr zone=conn_limit:10m;

    # ==========================================================================
    # API Load Balancer Server
    # ==========================================================================
    server {
        listen 80;
        server_name api.sql-studio.app;

        # Connection limiting
        limit_conn conn_limit 10;

        # Logging
        access_log /var/log/nginx/api-access.log upstream;
        error_log /var/log/nginx/api-error.log;

        # Health check endpoint (load balancer itself)
        location = /lb-health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }

        # Backend health check proxy
        location = /health {
            proxy_pass http://backend_api/health;
            proxy_http_version 1.1;
            proxy_set_header Connection "";

            # No caching for health checks
            proxy_cache_bypass 1;
            proxy_no_cache 1;

            # Short timeouts
            proxy_connect_timeout 2s;
            proxy_send_timeout 2s;
            proxy_read_timeout 2s;
        }

        # Authentication endpoints - strict rate limiting
        location ~ ^/api/v1/auth/(login|register|magic-link) {
            limit_req zone=auth_limit burst=3 nodelay;

            proxy_pass http://backend_api;
            include /etc/nginx/proxy_params.conf;

            # No caching for auth
            proxy_cache_bypass 1;
            proxy_no_cache 1;
        }

        # API endpoints - normal rate limiting
        location /api/ {
            limit_req zone=api_limit burst=50 nodelay;

            proxy_pass http://backend_api;
            include /etc/nginx/proxy_params.conf;

            # API caching (respects backend headers)
            proxy_cache api_cache;
            proxy_cache_valid 200 5m;
            proxy_cache_valid 404 1m;
            proxy_cache_bypass $http_cache_control;
            add_header X-Cache-Status $upstream_cache_status;
        }

        # WebSocket support
        location /ws/ {
            proxy_pass http://backend_api;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # WebSocket timeouts
            proxy_connect_timeout 7d;
            proxy_send_timeout 7d;
            proxy_read_timeout 7d;
        }

        # Default location
        location / {
            proxy_pass http://backend_api;
            include /etc/nginx/proxy_params.conf;
        }
    }

    # ==========================================================================
    # Frontend Load Balancer Server
    # ==========================================================================
    server {
        listen 80;
        server_name sql-studio.app www.sql-studio.app;

        # Logging
        access_log /var/log/nginx/frontend-access.log main;
        error_log /var/log/nginx/frontend-error.log;

        # Health check
        location = /health {
            proxy_pass http://frontend_web/health;
            proxy_http_version 1.1;
            proxy_set_header Connection "";

            proxy_connect_timeout 2s;
            proxy_send_timeout 2s;
            proxy_read_timeout 2s;
        }

        # Static assets - aggressive caching
        location ~* ^/assets/.*\.(js|css|png|jpg|jpeg|gif|svg|woff|woff2|ttf|eot)$ {
            proxy_pass http://frontend_web;
            include /etc/nginx/proxy_params.conf;

            proxy_cache static_cache;
            proxy_cache_valid 200 365d;
            proxy_cache_valid 404 1h;
            proxy_ignore_headers Cache-Control Set-Cookie;
            add_header X-Cache-Status $upstream_cache_status;

            # Long cache
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # API proxy (route to backend)
        location /api/ {
            proxy_pass http://backend_api;
            include /etc/nginx/proxy_params.conf;

            # No caching
            proxy_cache_bypass 1;
            proxy_no_cache 1;
        }

        # Default - proxy to frontend
        location / {
            proxy_pass http://frontend_web;
            include /etc/nginx/proxy_params.conf;

            # No caching for HTML
            proxy_cache_bypass 1;
            proxy_no_cache 1;
        }
    }

    # ==========================================================================
    # Metrics/Monitoring Server (Internal Only)
    # ==========================================================================
    server {
        listen 8080;
        server_name _;

        # Only allow from internal network
        allow 10.0.0.0/8;
        allow 172.16.0.0/12;
        allow 192.168.0.0/16;
        deny all;

        # nginx stub status
        location /nginx_status {
            stub_status on;
            access_log off;
        }

        # Backend upstream status
        location /upstream_status {
            # Requires nginx-module-vts or similar
            # vhost_traffic_status_display;
            # vhost_traffic_status_display_format html;
            return 200 "Use nginx-module-vts for detailed upstream stats\n";
        }

        # Health check
        location /health {
            access_log off;
            return 200 "load balancer healthy\n";
        }
    }
}

# =============================================================================
# Proxy Parameters File (/etc/nginx/proxy_params.conf)
# =============================================================================
# Create this file with common proxy settings:
#
# proxy_http_version 1.1;
# proxy_set_header Host $host;
# proxy_set_header X-Real-IP $remote_addr;
# proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
# proxy_set_header X-Forwarded-Proto $scheme;
# proxy_set_header X-Forwarded-Host $host;
# proxy_set_header X-Forwarded-Port $server_port;
# proxy_set_header Connection "";
#
# # Timeouts
# proxy_connect_timeout 60s;
# proxy_send_timeout 60s;
# proxy_read_timeout 60s;
#
# # Buffering
# proxy_buffering on;
# proxy_buffer_size 4k;
# proxy_buffers 8 4k;
# proxy_busy_buffers_size 8k;
#
# # Redirect handling
# proxy_redirect off;
#
# =============================================================================
# Health Check Match (nginx Plus)
# =============================================================================
# match health_ok {
#     status 200;
#     header Content-Type = "text/plain";
#     body ~ "healthy";
# }
#
# =============================================================================
# Usage Instructions
# =============================================================================
#
# 1. Deploy this config:
#    docker run -d \
#      -p 80:80 \
#      -p 8080:8080 \
#      -v $(pwd)/nginx-lb.conf:/etc/nginx/nginx.conf:ro \
#      -v $(pwd)/proxy_params.conf:/etc/nginx/proxy_params.conf:ro \
#      --name sql-studio-lb \
#      nginx:alpine
#
# 2. Update backend servers:
#    - Replace backend-1, backend-2, backend-3 with actual IPs/hostnames
#    - Adjust weights based on server capacity
#
# 3. Monitor status:
#    curl http://localhost:8080/nginx_status
#
# 4. Check logs:
#    docker logs -f sql-studio-lb
#
# 5. Reload config:
#    docker exec sql-studio-lb nginx -s reload
#
# 6. Test health check:
#    curl http://localhost/health
#
# =============================================================================
